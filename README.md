# ğŸ”¥ AgniPariksha â€“ Human or Bot Detection System

**AgniPariksha** (à¤…à¤—à¥à¤¨à¤¿à¤ªà¤°à¥€à¤•à¥à¤·à¤¾) â€” a term from Indian mythology meaning *â€œtrial by fireâ€* â€” was a symbolic test of purity and truth.  
This project carries that metaphor into the digital age, where the **trial** is not fire, but **behavior** â€” and the **truth** lies in how you move, type, and think.

**AgniPariksha** is a next-gen human verification system inspired by CAPTCHA â€” but smarter. Instead of image puzzles, it uses **behavioral and cognitive signals** to determine if a user is a human or a bot.

---

## ğŸš€ Features

- âœ… Tracks **keystrokes**, **mouse movements**, and **reaction time**
- âœ… Collects cognitive responses (e.g., question answering)
- âœ… Sends behavioral data to a **Flask backend**
- âœ… Uses an ML model to predict: **human vs bot**
- âœ… Displays prediction and confidence score on frontend

---

## ğŸ§  Architecture Overview

```txt
Frontend (React + Vite)
    |
    |-- Tracks user behavior (mouse, keyboard, time)
    |-- Sends data to backend via API
    |
Backend (Flask)
    |
    |-- Receives data from frontend
    |-- Extracts behavioral features
    |-- Feeds data to pre-trained ML model
    |-- Returns classification result (human/bot)
```

---

## ğŸ“ Project Structure

```bash
AgniPariksha/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                  # Flask entry point
â”‚   â”œâ”€â”€ routes/                 # Flask routes
â”‚   â”œâ”€â”€ models/                 # Saved ML models
â”‚   â”œâ”€â”€ utils/                  # Feature extraction logic
â”‚   â”œâ”€â”€ data/                   # Input data (ignored in git)
â”‚   â”œâ”€â”€ requirements.txt        # Backend dependencies
â”‚   â””â”€â”€ train_model.py          # Training logic
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ agni-ui/                # React frontend
â”‚       â”œâ”€â”€ node_modules/       # npm packages
â”‚       â”œâ”€â”€ src/                # Tracker.jsx & UI logic
â”‚       â”œâ”€â”€ public/             # Static assets
â”‚       â”œâ”€â”€ package.json        # Frontend dependencies
â”‚       â””â”€â”€ vite.config.js      # Vite config
â”‚
â”œâ”€â”€ venv/                       # Python virtual env (ignored)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ› ï¸ Installation Instructions

### ğŸ Backend (Flask + ML)

Create and activate virtual environment (from root):

```bash
python -m venv venv
.\venv\Scripts\activate      # Windows
source venv/bin/activate    # Linux/Mac
```

Install dependencies:

```bash
pip install -r backend/requirements.txt
```

Run the Flask server:

```bash
cd backend
python app.py
```

---

### ğŸŒ Frontend (React + Vite)

Navigate to the UI folder:

```bash
cd frontend/agni-ui
```

Install npm packages:

```bash
npm install
```

Start the frontend dev server:

```bash
npm run dev
```

---

## ğŸ§  ML Features Used

| Feature Name         | Description                                      |
|----------------------|--------------------------------------------------|
| `reaction_time`      | Time taken to respond after prompt appears       |
| `answer_length`      | Number of characters in the submitted response   |
| `avg_key_interval`   | Average time between keystrokes                  |
| `std_key_interval`   | Standard deviation of keystroke intervals        |
| `mouse_distance`     | Total distance of mouse movement during prompt   |
| `mouse_avg_speed`    | Average speed of mouse movements                 |
| `mouse_movements`    | Total count of mouse movement events             |

These features are passed to a trained machine learning model to classify users as either **human** or **bot** with a confidence score.

---



---

## ğŸ¤– Tech Stack

- **Frontend**: React, Vite, JavaScript, CSS
- **Backend**: Flask, Python
- **ML**: Scikit-learn, Pandas, NumPy
- **Dev Tools**: VS Code, Git, Postman
- **Deployment-ready**: Localhost (can extend to Render/Heroku/Netlify)

---

## ğŸ“¦ Future Ideas

- [ ] Add voice/audio-based verification
- [ ] Deploy the ML model on Hugging Face
- [ ] Add fallback classic CAPTCHA
- [ ] Build an admin dashboard to view logs and predictions
- [ ] Implement real-time heatmap visualizations of mouse movement

---

## ğŸ‘¨â€ğŸ’» Author

**Kshitij Hundre**  
[GitHub](https://github.com/alchemist240)  
[LinkedIn](https://in.linkedin.com/in/kshitij-hundre-b0a3602b0) <!-- Add your actual profile -->

---


Feel free to use, modify, and contribute!
